<!DOCTYPE html><html><head><title>MathJax TeX Test Page</title><link rel = "stylesheet" type = "text/css" href = "https://ychnh.github.io/style.css" /><meta name="viewport" content="width=device-width, initial-scale=1" /><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> </head> <body style="background-color:white;">
<p>lottery ticket hypothesus
* Attention
* LSTM tanh?</p>

<ul>
<li>Intrinsic Matrix</li>
<li>Recovering motion is same I think Need to figure out intrinsinc</li>
<li>Also re look at finding F I think it is same</li>
<li>Why all cameras llok same need to investigate thie recovery of motions as well understadning</li>
</ul>

<p>motion see if equiv if not change</p>

<ul>
<li>Music app to neuraly generate music that I like more deadmau5</li>
</ul>

<p>machine learn lasso
ligand reception and attachment
O Linked in</p>

<ul>
<li><p>ai chatbit project</p>

<ul>
<li>onlearn sound recognition and nlp intro</li>
<li>first with simple seq to seq next with bert </li>
</ul></li>
<li><p>drone localization guide</p>

<ul>
<li>https://towardsdatascience.com/monocular-3d-object-detection-in-autonomous-driving-2476a3c7f57e</li>
<li>in particular interested in the voxel based approach found in </li>
</ul></li>
</ul>

<h6>#</h6>

<h1>SLAM</h1>

<h6>#</h6>

<ul>
<li>Compare my algo with the other guy</li>
<li>use F first</li>
<li>only project inliers</li>
<li>dense reprojections</li>
<li>Intrinsic camera parameters</li>
</ul>

<h6>#</h6>

<h1>SCOPE</h1>

<h6>#</h6>

<p>O Repetitions in dist Ms? inspect per class information
* If there is repetition try adding noise and then evaluate model</p>

<p>x report
x loss going down but acc not need softmax
x Load our train2.0
x Split data into train/val
x Establish baseline
* Issue with shared batch data
  * requires grad?
  * Autograd understanding https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/
  * Deallocate training mem while doing batch testing</p>

<ul>
<li>Densenet Classifier</li>
<li>Add the large amounts of feature maps from generating the scope chains</li>
</ul>

<p>Housekeep
* Dataset access chains
* SCOPE Recalc dataset missing chains (Please iterate from zero)
Questions
* In a chain setting will the connections btw homology be consistent?</p>

<p>x Add validation and accuracy metric
x Verify batch size w/ backward
x Find max size for resolution
x Padding to Remove crop
x Train.py w/ loss
x Create dataset class
x Clean basic model add BN/Relu </p>

<h6>###############</h6>

<h1>GOALS</h1>

<h6>###############</h6>

<ul>
<li>SLAM - center motion recov</li>
<li>HOM CONV PRED</li>
<li>KAGGLE</li>
<li>LEARN NN Lit review</li>
<li>LEARN MATH</li>
<li><p>AI</p></li>
<li><p>Yabai Issue</p></li>
<li><p>Competition</p></li>
<li>Paper</li>
<li>Math</li>
<li>Personal Drone</li>
<li><p>Read an master material</p>

<ul>
<li>Alg</li>
<li>Lin Alg</li>
<li>ADV Calc</li>
<li>Analysis</li>
</ul></li>
<li><p>pwatch https://unix.stackexchange.com/questions/3842/how-can-i-scroll-within-the-output-of-my-watch-command</p></li>
<li><p>Understand Convolution backprop</p></li>
<li>Understand And backprop/grad fn</li>
<li>Spend 3 days studying math</li>
<li>Chatbot </li>
<li>RNN - Seq2Seq - LSTM - ELMO - BERT</li>
</ul>

<h6>###############</h6>

<h1>12/3</h1>

<p>0630-0700
* Commute to ainstudy
0700-0800
* dinner
0800-0900
* Presentation view at ainstudy
* Log of interesting clustering
0900-1000
* Commute and discussion on the way home
  * Main concerns with venture. Do you have the credentials
1000-1100
* Workout
1100-1140
* Relax recover eat protein 
* wash
1140-1247
* Inspect model output of features
  * Remove zero pad and calc reductions
  * Add hooks</p>

</body> </html>
