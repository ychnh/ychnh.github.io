#!/usr/bin/python3
import os
from os.path import join,exists
from os import system
from ytil import ytl
import argparse

MD = 'md'
HTML = 'html'
WEBROOT = 'https://ychnh.github.io/'

parser = argparse.ArgumentParser(description='Compile')
parser.add_argument('--f', metavar='N', type=bool, default=False, help='Force rebuild')
args = parser.parse_args()
if args.f:
    system('rm -r '+HTML)


def os_remove(p):
    if os.path.exists(p): os.remove(p)

def BIJ_md_html(html):
    md = 'md'+html[4:-4]+'md'
    return md

def BIJ_html_md(md):
    html = 'html' + md[2:-2]+'html'
    return html

def path_split(p):
    a,b = os.path.split(p)
    return path_split(a)+[b]


def requires_compile_md(fp_md):
    if args.f:
        return True

    fp_html = get_fphtml(fp_md)
    if not exists(fp_html):
        return True
    return os.path.getmtime(fp_md) >= os.path.getmtime(fp_html)


def dirname(d):
    return './'+'/'.join( d.split('/')[1:] )

def comp(fp_md, fp_html):
    dirs = '/'.join( fp_html.split('/')[:-1] )

    if dirs!='' and not os.path.exists(dirs):
        os.makedirs(dirs)


    system('./compile '+fp_md+' '+fp_html)

def md_link_str(name,link):
    return '['+name+']'+'('+link+')'

def build_index(FP_html):
    idnt = '  '
    index_lines = []

    for data in FP_html:
        t = data['type']
        if t == 'dir':
            n = data['name']
            splits = n.split('/')
            try: splits.remove('')
            except ValueError: pass
            #k = len( splits )
            #index_lines.append(  k*'#'+' '+n )
            k = len( splits )-2
            index_lines.append(  k*idnt+'* '+n )
        elif t == 'link':
            n,l = data['name'], data['link']
            k = n.count('/')
            index_lines.append(  k*idnt+'* '+ md_link_str(n,l) )

    print('\n'.join(index_lines) )
    fp_index = 'index.md'
    ytl.writeListToFile(index_lines,fp_index)
    comp(fp_index, 'index.html')



FP_html = []

def get_fphtml(fpmd):
    fp_html = fp_md[:-3] + '.html'
    fp_html = fp_html.replace(MD,HTML,1)
    return fp_html


exclude = ['.git', '.ipynb_checkpoints','__pycache__', 'ytil', 'ignore']


for root, dirs, files in os.walk(MD, topdown=True):
    if os.path.basename(root) in exclude: continue
    dirs[:] = [d for d in dirs if d not in exclude]


    FP_html.append( {'name':dirname(root),'type':'dir'})

    for f in files:
        if f[-3:] == '.md':
            fp_md = join(root,f) 
            fp_html = get_fphtml(fp_md)
            if requires_compile_md(fp_md):
                comp(fp_md, fp_html)
            name = fp_html[5:]
            link = WEBROOT+ fp_html
            FP_html.append( {'name':name, 'link':link,'type':'link'})

build_index(FP_html)



# CLEAN ########################################################
def get_files_recursive(dir):
    FILES = []
    for root, dirs, files in os.walk(dir, topdown=True):
        for f in files:
            FILES.append( str(join(root, f)) )
    return FILES

print('removing unlinked html')
MD_FILES = get_files_recursive(MD)
HTML_FILES = get_files_recursive(HTML)
for h in HTML_FILES:
    fp_md = BIJ_md_html(h)
    if not (fp_md in MD_FILES):
        os_remove( h )
        print(h)

print('removing empty directories')
for root,_,_ in os.walk(HTML, topdown=True):
    if len( os.listdir(root) ) == 0:
        os.rmdir(root)
        print( root )
